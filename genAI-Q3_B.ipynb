{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e60zukDaG1u4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    Helper module to generate sinusoidal timestep embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard residual block for the U-Net, which also incorporates\n",
        "    time and class embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, time_emb_dim, num_classes=None, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.GroupNorm(32, in_channels), # This GroupNorm applies to the input of conv1\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.GroupNorm(32, out_channels), # This GroupNorm applies to the output of conv1 and input of conv2\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # Linear layers for time and class embeddings\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, out_channels)\n",
        "        )\n",
        "\n",
        "        self.class_mlp = None\n",
        "        if num_classes is not None:\n",
        "            self.class_mlp = nn.Sequential(\n",
        "                nn.SiLU(),\n",
        "                nn.Linear(time_emb_dim, out_channels) # Use time_emb_dim for class emb as well\n",
        "            )\n",
        "\n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb, c_emb=None):\n",
        "        h = self.conv1(x)\n",
        "\n",
        "        # Add time embedding\n",
        "        time_cond = self.time_mlp(t_emb)\n",
        "        h = h + time_cond.unsqueeze(-1).unsqueeze(-1) # Reshape to (B, C, 1, 1)\n",
        "\n",
        "        # Add class embedding\n",
        "        if c_emb is not None and self.class_mlp is not None:\n",
        "            class_cond = self.class_mlp(c_emb)\n",
        "            h = h + class_cond.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        h = self.conv2(h)\n",
        "        return h + self.shortcut(x)\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple multi-head self-attention block.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.norm = nn.GroupNorm(32, channels)\n",
        "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1, bias=False)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=channels, num_heads=num_heads, batch_first=True)\n",
        "        self.proj_out = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        h = self.norm(x)\n",
        "\n",
        "        qkv = self.qkv(h)\n",
        "        qkv = qkv.reshape(B, 3 * C, H * W).permute(0, 2, 1) # (B, H*W, 3*C)\n",
        "        q, k, v = qkv.chunk(3, dim=-1) # (B, H*W, C) each\n",
        "\n",
        "        # Use torch.nn.MultiheadAttention\n",
        "        # Note: MHA expects (L, N, E) or (N, L, E) if batch_first=True\n",
        "        # Here N=B, L=H*W, E=C\n",
        "        attn_output, _ = self.attention(q, k, v)\n",
        "\n",
        "        attn_output = attn_output.permute(0, 2, 1).reshape(B, C, H, W) # (B, C, H, W)\n",
        "        return x + self.proj_out(attn_output)\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A downsampling block in the U-Net.\n",
        "    (ResidualBlock -> ResidualBlock -> Attention -> Downsample)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, time_emb_dim, num_classes, has_attn=False, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.res1 = ResidualBlock(in_channels, out_channels, time_emb_dim, num_classes, dropout)\n",
        "        self.res2 = ResidualBlock(out_channels, out_channels, time_emb_dim, num_classes, dropout)\n",
        "        self.attn = AttentionBlock(out_channels) if has_attn else nn.Identity()\n",
        "        self.downsample = nn.Conv2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x, t_emb, c_emb):\n",
        "        x = self.res1(x, t_emb, c_emb)\n",
        "        x = self.res2(x, t_emb, c_emb)\n",
        "        x = self.attn(x)\n",
        "        skip = x # Save for skip connection\n",
        "        out = self.downsample(x)\n",
        "        return out, skip\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    An upsampling block in the U-Net.\n",
        "    (Upsample -> Concat Skip -> ResidualBlock -> ResidualBlock -> Attention)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, time_emb_dim, num_classes,\n",
        "                 has_attn=False, dropout=0.1, up_in_channels=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # 'in_channels' is the channel count for res1 (after skip-cat)\n",
        "        # 'out_channels' is the final output channel count for this block\n",
        "        # 'up_in_channels' is the input channel count for the upsample layer (from layer below)\n",
        "\n",
        "        if up_in_channels is None:\n",
        "            up_in_channels = in_channels // 2 # Fallback, but we will provide it\n",
        "\n",
        "        self.res1 = ResidualBlock(in_channels, out_channels, time_emb_dim, num_classes, dropout)\n",
        "        self.res2 = ResidualBlock(out_channels, out_channels, time_emb_dim, num_classes, dropout)\n",
        "        self.attn = AttentionBlock(out_channels) if has_attn else nn.Identity()\n",
        "\n",
        "        # *** THIS IS THE FIX ***\n",
        "        # The upsample layer takes 'up_in_channels' and upsamples to 'out_channels'.\n",
        "        self.upsample = nn.ConvTranspose2d(up_in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x, skip, t_emb, c_emb):\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([skip, x], dim=1) # Concatenate skip connection\n",
        "        x = self.res1(x, t_emb, c_emb)\n",
        "        x = self.res2(x, t_emb, c_emb)\n",
        "        x = self.attn(x)\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    \"\"\"\n",
        "    The full U-Net model.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_channels=3,\n",
        "        init_channels=64,\n",
        "        dim_mults=(1, 2, 4), # Controls depth and channel count\n",
        "        num_classes=2,       # Set to 2 for \"cat\" and \"dog\"\n",
        "        time_emb_dim=256,    # Should be 4 * init_channels\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # == 1. Time and Class Embeddings ==\n",
        "        self.time_embed = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim)\n",
        "        )\n",
        "\n",
        "        if num_classes is not None:\n",
        "            self.class_embed = nn.Embedding(num_classes, time_emb_dim)\n",
        "\n",
        "        # == 2. Initial Convolution ==\n",
        "        self.init_conv = nn.Conv2d(image_channels, init_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        # == 3. Downsampling Path (Encoder) ==\n",
        "        self.down_blocks = nn.ModuleList()\n",
        "        channels = [init_channels]\n",
        "        now_channels = init_channels\n",
        "\n",
        "        for i, mult in enumerate(dim_mults):\n",
        "            out_channels = init_channels * mult\n",
        "            self.down_blocks.append(\n",
        "                DownBlock(\n",
        "                    now_channels,\n",
        "                    out_channels,\n",
        "                    time_emb_dim,\n",
        "                    num_classes,\n",
        "                    has_attn=(i >= (len(dim_mults) - 2)), # Add attention at 8x8\n",
        "                    dropout=dropout\n",
        "                )\n",
        "            )\n",
        "            now_channels = out_channels\n",
        "            channels.append(now_channels)\n",
        "\n",
        "        # == 4. Bottleneck ==\n",
        "        self.mid_block1 = ResidualBlock(now_channels, now_channels, time_emb_dim, num_classes, dropout)\n",
        "        self.mid_attn = AttentionBlock(now_channels)\n",
        "        self.mid_block2 = ResidualBlock(now_channels, now_channels, time_emb_dim, num_classes, dropout)\n",
        "# == 5. Upsampling Path (Decoder) ==\n",
        "        self.up_blocks = nn.ModuleList()\n",
        "\n",
        "        # 'now_channels' is 256 (from bottleneck)\n",
        "        # 'channels' list is [64, 64, 128, 256] (from down path)\n",
        "\n",
        "        for i, mult in reversed(list(enumerate(dim_mults))):\n",
        "            out_channels = init_channels * mult  # e.g., 256, then 128, then 64\n",
        "\n",
        "            # Get skip channels from corresponding down block\n",
        "            # i=2 -> channels[3] = 256\n",
        "            # i=1 -> channels[2] = 128\n",
        "            # i=0 -> channels[1] = 64\n",
        "            skip_channels = channels[i+1]\n",
        "\n",
        "            # *** THIS IS THE FIX ***\n",
        "            # The input to the first ResBlock is the concatenated tensor,\n",
        "            # which has 'out_channels' (from upsampling) + 'skip_channels'.\n",
        "            # The old code incorrectly used 'now_channels'.\n",
        "            in_channels_res1 = out_channels + skip_channels\n",
        "\n",
        "            self.up_blocks.append(\n",
        "                UpBlock(\n",
        "                    in_channels = in_channels_res1,    # Channels for ResBlock (e.g., 128+128=256)\n",
        "                    out_channels = out_channels,       # Channels for output of this block (e.g., 128)\n",
        "                    time_emb_dim = time_emb_dim,\n",
        "                    num_classes = num_classes,\n",
        "                    has_attn = (i >= (len(dim_mults) - 2)),\n",
        "                    dropout = dropout,\n",
        "                    up_in_channels = now_channels    # Channels from layer below (e.g., 256)\n",
        "                )\n",
        "            )\n",
        "            now_channels = out_channels # Update for next loop (e.g., 128, then 64)\n",
        "\n",
        "        # == 6. Final Convolution ==\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.GroupNorm(32, init_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(init_channels, image_channels, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, time, y=None):\n",
        "        \"\"\"\n",
        "        x: Noisy image (B, C, H, W)\n",
        "        time: Timestep (B,)\n",
        "        y: Class label (B,)\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. Get embeddings\n",
        "        t_emb = self.time_embed(time)\n",
        "\n",
        "        c_emb = None\n",
        "        if y is not None and self.num_classes is not None:\n",
        "            c_emb = self.class_embed(y)\n",
        "            # You can combine embeddings, e.g., by adding\n",
        "            t_emb = t_emb + c_emb\n",
        "\n",
        "        # 2. Initial conv\n",
        "        x = self.init_conv(x) # (B, 64, 32, 32)\n",
        "\n",
        "        # 3. Down path\n",
        "        skips = [x]\n",
        "        for block in self.down_blocks:\n",
        "            x, skip = block(x, t_emb, c_emb)\n",
        "            skips.append(skip)\n",
        "\n",
        "        # 4. Bottleneck\n",
        "        x = self.mid_block1(x, t_emb, c_emb)\n",
        "        x = self.mid_attn(x)\n",
        "        x = self.mid_block2(x, t_emb, c_emb)\n",
        "\n",
        "        # 5. Up path\n",
        "        for block in self.up_blocks:\n",
        "            x = block(x, skips.pop(), t_emb, c_emb)\n",
        "\n",
        "        # 6. Final output\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # --- Parameters for CIFAR-10 (32x32) ---\n",
        "    BATCH_SIZE = 8\n",
        "    IMG_SIZE = 32\n",
        "    IMG_CHANNELS = 3\n",
        "    NUM_CLASSES = 2 # As requested: \"cat\" and \"dog\"\n",
        "\n",
        "    # 1. Create a dummy batch of data\n",
        "    # Noisy images\n",
        "    x = torch.randn(BATCH_SIZE, IMG_CHANNELS, IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "    # Random timesteps (from 0 to, e.g., 1000)\n",
        "    t = torch.randint(0, 1000, (BATCH_SIZE,))\n",
        "\n",
        "    # Random class labels (0 or 1)\n",
        "    y = torch.randint(0, NUM_CLASSES, (BATCH_SIZE,))\n",
        "\n",
        "    # 2. Instantiate the U-Net\n",
        "    # We use small channel dimensions for a 32x32 image\n",
        "    # dim_mults=(1, 2, 4) -> 32x32 -> 16x16 -> 8x8 -> 4x4 (bottleneck)\n",
        "    model = Unet(\n",
        "        image_channels=IMG_CHANNELS,\n",
        "        init_channels=64,\n",
        "        dim_mults=(1, 2, 4),\n",
        "        num_classes=NUM_CLASSES,\n",
        "        time_emb_dim=256 # 64 * 4\n",
        "    )\n",
        "\n",
        "    print(f\"Model parameter count: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "\n",
        "    # 3. Run the forward pass\n",
        "    # The model predicts the noise (or v, depending on your objective)\n",
        "    predicted_noise = model(x, t, y)\n",
        "\n",
        "    print(f\"Input shape:   {x.shape}\")\n",
        "    print(f\"Output shape:  {predicted_noise.shape}\")\n",
        "\n",
        "    # Check if output shape matches input shape\n",
        "    assert x.shape == predicted_noise.shape\n",
        "\n",
        "    print(\"\\nSuccess! Model forward pass is working correctly.\")\n",
        "\n",
        "    # --- Example without class conditioning ---\n",
        "    model_unconditional = Unet(num_classes=None)\n",
        "    predicted_noise_uncond = model_unconditional(x, t, y=None) # Pass y=None\n",
        "    print(f\"\\nUnconditional output shape: {predicted_noise_uncond.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwfSYGTiIVWH",
        "outputId": "223b7e53-b7a0-4ae3-82b0-9f5695487acf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameter count: 15.43M\n",
            "Input shape:   torch.Size([8, 3, 32, 32])\n",
            "Output shape:  torch.Size([8, 3, 32, 32])\n",
            "\n",
            "Success! Model forward pass is working correctly.\n",
            "\n",
            "Unconditional output shape: torch.Size([8, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from tqdm import tqdm  # For a nice progress bar\n",
        "import numpy as np\n",
        "\n",
        "# We assume your Unet model is in a file named unet.py\n",
        "# (No import needed if running in the same notebook)\n",
        "\n",
        "\n",
        "# --- 1. Diffusion Scheduler ---\n",
        "# This helper class manages the noise schedule (betas, alphas)\n",
        "# and provides functions for the v-prediction objective.\n",
        "\n",
        "class LinearNoiseScheduler:\n",
        "    \"\"\"\n",
        "    A linear noise scheduler as described in the DDPM paper,\n",
        "    with added support for v-prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
        "        self.num_timesteps = num_timesteps\n",
        "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
        "\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "        # Pre-calculate values for diffusion step\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
        "\n",
        "\n",
        "    def add_noise(self, x_0, t, noise):\n",
        "        \"\"\"\n",
        "        Adds noise to the original image x_0 to get x_t.\n",
        "        x_t = sqrt(alpha_bar_t) * x_0 + sqrt(1 - alpha_bar_t) * noise\n",
        "        \"\"\"\n",
        "        shape = x_0.shape\n",
        "\n",
        "        # --- THIS IS THE FIX ---\n",
        "        # Call the 3-argument _get_tensor_values for BOTH schedules\n",
        "        sqrt_alpha_bar_t = self._get_tensor_values(\n",
        "            t, shape, self.sqrt_alphas_cumprod\n",
        "        )\n",
        "        sqrt_one_minus_alpha_bar_t = self._get_tensor_values(\n",
        "            t, shape, self.sqrt_one_minus_alphas_cumprod\n",
        "        )\n",
        "        # --- END OF FIX ---\n",
        "\n",
        "        noisy_image = sqrt_alpha_bar_t * x_0 + sqrt_one_minus_alpha_bar_t * noise\n",
        "        return noisy_image\n",
        "\n",
        "    def get_velocity(self, x_0, t, noise):\n",
        "        \"\"\"\n",
        "        Calculates the target 'v' for v-prediction.\n",
        "        v = sqrt(alpha_bar_t) * noise - sqrt(1 - alpha_bar_t) * x_0\n",
        "        \"\"\"\n",
        "        shape = x_0.shape\n",
        "\n",
        "        # Note: Fixed a bug here from the original paste.\n",
        "        # get_velocity also needs to call the 3-argument version correctly.\n",
        "        sqrt_alpha_bar_t = self._get_tensor_values(\n",
        "            t, shape, self.sqrt_alphas_cumprod\n",
        "        )\n",
        "        sqrt_one_minus_alpha_bar_t = self._get_tensor_values(\n",
        "            t, shape, self.sqrt_one_minus_alphas_cumprod\n",
        "        )\n",
        "\n",
        "        velocity = sqrt_alpha_bar_t * noise - sqrt_one_minus_alpha_bar_t * x_0\n",
        "        return velocity\n",
        "\n",
        "    # We need to override this one method for v-prediction\n",
        "    def _get_tensor_values(self, t, shape, schedule_tensor):\n",
        "        batch_size = t.shape[0]\n",
        "        out = schedule_tensor.to(t.device).gather(-1, t)\n",
        "        return out.reshape(batch_size, *((1,) * (len(shape) - 1)))\n",
        "\n",
        "\n",
        "# --- 2. Dataset Loader ---\n",
        "\n",
        "def get_dataloader(batch_size, num_classes=2):\n",
        "    \"\"\"\n",
        "    Loads the CIFAR-10 dataset, filtered for two classes.\n",
        "    \"\"\"\n",
        "    # CIFAR-10 classes: ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "    #                    'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    CAT_CLASS = 3\n",
        "    DOG_CLASS = 5\n",
        "\n",
        "    # Standard normalization for diffusion models\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),                # To [0, 1]\n",
        "        transforms.Normalize((0.5,), (0.5,))  # To [-1, 1]\n",
        "    ])\n",
        "\n",
        "    dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "    # Filter for \"cat\" and \"dog\"\n",
        "    indices = [i for i, (_, label) in enumerate(dataset) if label in [CAT_CLASS, DOG_CLASS]]\n",
        "\n",
        "    # Create a new label mapping: 0 for cat, 1 for dog\n",
        "    # We must do this *after* filtering\n",
        "    for i in range(len(dataset.targets)):\n",
        "        if dataset.targets[i] == CAT_CLASS:\n",
        "            dataset.targets[i] = 0\n",
        "        elif dataset.targets[i] == DOG_CLASS:\n",
        "            dataset.targets[i] = 1\n",
        "\n",
        "    filtered_dataset = Subset(dataset, indices)\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        filtered_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "# --- 3. Training Script ---\n",
        "\n",
        "def train():\n",
        "    # --- Hyperparameters (from your project) ---\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    LEARNING_RATE = 1e-4\n",
        "    BATCH_SIZE = 256  # As specified\n",
        "    NUM_EPOCHS = 100  # You'll need to run this for many epochs\n",
        "    NUM_TIMESTEPS = 250 # As specified (use this for scheduler)\n",
        "    NUM_CLASSES = 2     # \"cat\" and \"dog\"\n",
        "\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    # --- Setup ---\n",
        "    # 1. Model\n",
        "    model = Unet(\n",
        "        image_channels=3,\n",
        "        init_channels=64,\n",
        "        dim_mults=(1, 2, 4),\n",
        "        num_classes=NUM_CLASSES,\n",
        "        time_emb_dim=256\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # 2. Dataloader\n",
        "    dataloader = get_dataloader(BATCH_SIZE, NUM_CLASSES)\n",
        "\n",
        "    # 3. Scheduler (with v-prediction)\n",
        "    scheduler = LinearNoiseScheduler(num_timesteps=NUM_TIMESTEPS)\n",
        "\n",
        "    # 4. Optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # 5. Loss Function\n",
        "    loss_fn = F.mse_loss\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # Use tqdm for a progress bar\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", leave=True)\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            images, labels = batch\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # 1. Sample random noise\n",
        "            noise = torch.randn_like(images).to(DEVICE)\n",
        "\n",
        "            # 2. Sample random timesteps\n",
        "            t = torch.randint(0, scheduler.num_timesteps, (images.shape[0],)).to(DEVICE)\n",
        "\n",
        "            # 3. Create noisy images (x_t)\n",
        "            noisy_images = scheduler.add_noise(images, t, noise)\n",
        "\n",
        "            # 4. Get model prediction (predict v)\n",
        "            # We set labels to None 10% of the time for classifier-free guidance\n",
        "            if np.random.rand() < 0.1:\n",
        "                labels = None\n",
        "\n",
        "            predicted_v = model(noisy_images, t, labels)\n",
        "\n",
        "            # 5. Get target velocity (target v)\n",
        "            target_v = scheduler.get_velocity(images, t, noise)\n",
        "\n",
        "            # 6. Calculate loss\n",
        "            loss = loss_fn(predicted_v, target_v)\n",
        "\n",
        "            # 7. Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix(Loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1} finished. Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # --- Save a checkpoint (optional but recommended) ---\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            torch.save(model.state_dict(), f\"unet_cifar10_epoch_{epoch+1}.pth\")\n",
        "            print(f\"Saved model checkpoint at epoch {epoch+1}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    torch.save(model.state_dict(), \"unet_cifar10_final.pth\")\n",
        "\n",
        "# This check won't work in a notebook cell,\n",
        "# you should just call train() directly.\n",
        "# if __name__ == \"__main__\":\n",
        "#     train()\n",
        "\n",
        "# Call train() directly in your notebook cell\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YyqtDRaKpRN",
        "outputId": "d19141ee-2ca5-442b-cbb8-4c4a68ee556e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 40/40 [00:26<00:00,  1.51it/s, Loss=0.354]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished. Average Loss: 0.4810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.262]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished. Average Loss: 0.2963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 40/40 [00:25<00:00,  1.54it/s, Loss=0.218]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished. Average Loss: 0.2335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished. Average Loss: 0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished. Average Loss: 0.1962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished. Average Loss: 0.1825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished. Average Loss: 0.1723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished. Average Loss: 0.1661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished. Average Loss: 0.1636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 40/40 [00:25<00:00,  1.55it/s, Loss=0.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished. Average Loss: 0.1585\n",
            "Saved model checkpoint at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.149]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished. Average Loss: 0.1569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished. Average Loss: 0.1527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.153]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished. Average Loss: 0.1502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished. Average Loss: 0.1504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished. Average Loss: 0.1469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished. Average Loss: 0.1453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished. Average Loss: 0.1415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished. Average Loss: 0.1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished. Average Loss: 0.1415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 40/40 [00:25<00:00,  1.55it/s, Loss=0.155]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished. Average Loss: 0.1423\n",
            "Saved model checkpoint at epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.166]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 finished. Average Loss: 0.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 finished. Average Loss: 0.1348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 finished. Average Loss: 0.1319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.108]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 finished. Average Loss: 0.1310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 finished. Average Loss: 0.1319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 finished. Average Loss: 0.1278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 finished. Average Loss: 0.1295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 finished. Average Loss: 0.1312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 finished. Average Loss: 0.1247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 finished. Average Loss: 0.1267\n",
            "Saved model checkpoint at epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 finished. Average Loss: 0.1252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0947]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 finished. Average Loss: 0.1235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.0946]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 finished. Average Loss: 0.1246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 finished. Average Loss: 0.1258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 finished. Average Loss: 0.1258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.108]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 finished. Average Loss: 0.1228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 finished. Average Loss: 0.1212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.122]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 finished. Average Loss: 0.1225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.145]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 finished. Average Loss: 0.1233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 finished. Average Loss: 0.1208\n",
            "Saved model checkpoint at epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 finished. Average Loss: 0.1209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 finished. Average Loss: 0.1206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 finished. Average Loss: 0.1216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 finished. Average Loss: 0.1213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.109]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 finished. Average Loss: 0.1174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 finished. Average Loss: 0.1177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 finished. Average Loss: 0.1171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0992]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 finished. Average Loss: 0.1190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 finished. Average Loss: 0.1195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 finished. Average Loss: 0.1179\n",
            "Saved model checkpoint at epoch 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 finished. Average Loss: 0.1167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 finished. Average Loss: 0.1168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 finished. Average Loss: 0.1167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0776]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 finished. Average Loss: 0.1149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0959]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 finished. Average Loss: 0.1154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 finished. Average Loss: 0.1156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 finished. Average Loss: 0.1139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0963]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 finished. Average Loss: 0.1139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0955]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 finished. Average Loss: 0.1153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 finished. Average Loss: 0.1146\n",
            "Saved model checkpoint at epoch 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 finished. Average Loss: 0.1157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.155]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 finished. Average Loss: 0.1150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 finished. Average Loss: 0.1137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 finished. Average Loss: 0.1129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.138]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 finished. Average Loss: 0.1129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 finished. Average Loss: 0.1118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0954]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 finished. Average Loss: 0.1129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 finished. Average Loss: 0.1119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 finished. Average Loss: 0.1107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 finished. Average Loss: 0.1127\n",
            "Saved model checkpoint at epoch 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 finished. Average Loss: 0.1121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 finished. Average Loss: 0.1112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.095]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 finished. Average Loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.0964]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 finished. Average Loss: 0.1119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 finished. Average Loss: 0.1108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.123]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 finished. Average Loss: 0.1113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.106]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 finished. Average Loss: 0.1112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 finished. Average Loss: 0.1094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.0917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 finished. Average Loss: 0.1093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.0847]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 finished. Average Loss: 0.1091\n",
            "Saved model checkpoint at epoch 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.137]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 finished. Average Loss: 0.1105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 finished. Average Loss: 0.1097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.0666]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 finished. Average Loss: 0.1092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.0847]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 finished. Average Loss: 0.1095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 finished. Average Loss: 0.1080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.109]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 finished. Average Loss: 0.1085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0969]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 finished. Average Loss: 0.1086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.0792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 finished. Average Loss: 0.1084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 finished. Average Loss: 0.1071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 finished. Average Loss: 0.1099\n",
            "Saved model checkpoint at epoch 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.089]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 finished. Average Loss: 0.1073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.0783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 finished. Average Loss: 0.1091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 finished. Average Loss: 0.1071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 finished. Average Loss: 0.1080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.0796]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 finished. Average Loss: 0.1067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.0896]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 finished. Average Loss: 0.1064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 40/40 [00:25<00:00,  1.55it/s, Loss=0.149]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 finished. Average Loss: 0.1094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 40/40 [00:25<00:00,  1.56it/s, Loss=0.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 finished. Average Loss: 0.1075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s, Loss=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 finished. Average Loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s, Loss=0.102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 finished. Average Loss: 0.1067\n",
            "Saved model checkpoint at epoch 100\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- 1. INFERENCE FUNCTION (SAMPLER) ---\n",
        "\n",
        "def generate_images(\n",
        "    model,\n",
        "    scheduler,\n",
        "    num_images=16,\n",
        "    class_label=0,  # 0 for \"cat\", 1 for \"dog\"\n",
        "    guidance_scale=5.0,\n",
        "    device=\"cuda\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates images using the trained U-Net and a DDPM-style sampler.\n",
        "    This sampler is specifically adapted for a v-prediction model.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Setup ---\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    num_timesteps = scheduler.num_timesteps\n",
        "\n",
        "    # Start with random noise x_T\n",
        "    # Shape: (batch_size, channels, height, width)\n",
        "    img = torch.randn(num_images, 3, 32, 32, device=device)\n",
        "\n",
        "    # Create the label tensor\n",
        "    labels = torch.full((num_images,), class_label, dtype=torch.long, device=device)\n",
        "\n",
        "    # --- 2. Pre-calculate sampler constants ---\n",
        "    # We need these for the DDPM sampling formula\n",
        "    betas = scheduler.betas.to(device)\n",
        "    alphas = scheduler.alphas.to(device)\n",
        "    alphas_cumprod = scheduler.alphas_cumprod.to(device)\n",
        "\n",
        "    # Pre-calculated terms for x_t-1\n",
        "    # 1 / sqrt(alpha_t)\n",
        "    sqrt_recip_alphas_t = (1.0 / torch.sqrt(alphas)).to(device)\n",
        "\n",
        "    # (1 - alpha_t) / sqrt(1 - alpha_bar_t)\n",
        "    beta_over_sqrt_one_minus_alpha_bar_t = ((1. - alphas) / torch.sqrt(1. - alphas_cumprod)).to(device)\n",
        "\n",
        "    # Posterior variance: (1 - alpha_bar_t-1) / (1 - alpha_bar_t) * beta_t\n",
        "    alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "    posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "    # We use the log for stability and clipping\n",
        "    posterior_log_variance = torch.log(posterior_variance.clamp(min=1e-20))\n",
        "\n",
        "    # --- 3. The Sampling Loop ---\n",
        "    print(f\"Generating {num_images} images of class '{'cat' if class_label==0 else 'dog'}'...\")\n",
        "\n",
        "    # Loop from T (num_timesteps - 1) down to 0\n",
        "    for t in tqdm(reversed(range(num_timesteps)), desc=\"Sampling\"):\n",
        "        # Create a tensor of the current timestep, duplicated for each image in batch\n",
        "        t_tensor = torch.full((num_images,), t, dtype=torch.long, device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # --- a. Classifier-Free Guidance (CFG) ---\n",
        "            # First, predict v_uncond (with labels=None)\n",
        "            v_uncond = model(img, t_tensor, y=None)\n",
        "\n",
        "            # Second, predict v_cond (with our target labels)\n",
        "            v_cond = model(img, t_tensor, y=labels)\n",
        "\n",
        "            # Combine them: v = v_uncond + scale * (v_cond - v_uncond)\n",
        "            pred_v = v_uncond + guidance_scale * (v_cond - v_uncond)\n",
        "\n",
        "            # --- b. Convert v-prediction to epsilon-prediction ---\n",
        "            # We need epsilon for the DDPM sampling formula\n",
        "            # pred_epsilon = sqrt(1 - alpha_bar_t) * x_t + sqrt(alpha_bar_t) * pred_v\n",
        "            sqrt_alpha_bar_t = scheduler._get_tensor_values(\n",
        "                t_tensor, img.shape, scheduler.sqrt_alphas_cumprod\n",
        "            )\n",
        "            sqrt_one_minus_alpha_bar_t = scheduler._get_tensor_values(\n",
        "                t_tensor, img.shape, scheduler.sqrt_one_minus_alphas_cumprod\n",
        "            )\n",
        "\n",
        "            pred_epsilon = sqrt_one_minus_alpha_bar_t * img + sqrt_alpha_bar_t * pred_v\n",
        "\n",
        "        # --- c. DDPM Sampling Step ---\n",
        "        # Get the pre-calculated coefficients for this timestep t\n",
        "        mean_scale_t = sqrt_recip_alphas_t[t].reshape(-1, 1, 1, 1)\n",
        "        noise_coeff_t = beta_over_sqrt_one_minus_alpha_bar_t[t].reshape(-1, 1, 1, 1)\n",
        "        log_variance_t = posterior_log_variance[t].reshape(-1, 1, 1, 1)\n",
        "\n",
        "        # 1. Calculate the mean of x_{t-1}\n",
        "        # x_{t-1}_mean = (1/sqrt(alpha_t)) * (x_t - (beta_t / sqrt(1 - alpha_bar_t)) * epsilon_t)\n",
        "        pred_x_t_minus_1_mean = mean_scale_t * (img - noise_coeff_t * pred_epsilon)\n",
        "\n",
        "        # 2. Add noise\n",
        "        if t > 0:\n",
        "            noise = torch.randn_like(img)\n",
        "            # variance = exp(log_variance) * noise\n",
        "            # (we take 0.5 * log_variance because it's log(sigma^2) and we want sigma)\n",
        "            pred_x_t_minus_1 = pred_x_t_minus_1_mean + (0.5 * log_variance_t).exp() * noise\n",
        "        else:\n",
        "            # At t=0, there is no noise\n",
        "            pred_x_t_minus_1 = pred_x_t_minus_1_mean\n",
        "\n",
        "        # Update our image for the next loop iteration\n",
        "        img = pred_x_t_minus_1\n",
        "\n",
        "    # --- 4. Post-process and Return ---\n",
        "    # Undo the normalization from [-1, 1] back to [0, 1]\n",
        "    img = (img.clamp(-1, 1) + 1) / 2\n",
        "    # Convert to [0, 255] for saving as an image file\n",
        "    img = (img * 255).type(torch.uint8)\n",
        "\n",
        "    return img\n",
        "\n",
        "# --- 2. SCRIPT TO RUN THE INFERENCE ---\n",
        "\n",
        "# --- Setup Model and Scheduler ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_TIMESTEPS = 250\n",
        "NUM_CLASSES = 2\n",
        "CHECKPOINT_PATH = \"unet_cifar10_epoch_100.pth\" # Or \"unet_cifar10_final.pth\"\n",
        "\n",
        "# 1. Load your trained model\n",
        "# (This assumes the 'Unet' class is already defined in a previous cell)\n",
        "model = Unet(\n",
        "    image_channels=3,\n",
        "    init_channels=64,\n",
        "    dim_mults=(1, 2, 4),\n",
        "    num_classes=NUM_CLASSES,\n",
        "    time_emb_dim=256\n",
        ").to(DEVICE)\n",
        "\n",
        "# Load the checkpoint file from training\n",
        "model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))\n",
        "\n",
        "# 2. Create the scheduler\n",
        "# (This assumes the 'LinearNoiseScheduler' class is already defined)\n",
        "scheduler = LinearNoiseScheduler(num_timesteps=NUM_TIMESTEPS)\n",
        "\n",
        "\n",
        "# --- Generate \"Cat\" images (class_label=0) ---\n",
        "print(\"--- Generating Cats ---\")\n",
        "generated_cats = generate_images(\n",
        "    model,\n",
        "    scheduler,\n",
        "    num_images=16,\n",
        "    class_label=0,  # 0 for cat\n",
        "    guidance_scale=5.0,\n",
        "    device=DEVICE\n",
        ")\n",
        "\n",
        "# Save the cat images\n",
        "save_image(\n",
        "    generated_cats.float() / 255.0,  # Convert from [0, 255] to [0, 1]\n",
        "    \"generated_cats_epoch_100.png\",\n",
        "    nrow=4  # Create a 4x4 grid\n",
        ")\n",
        "print(\"Saved cat images to 'generated_cats_epoch_100.png'\")\n",
        "\n",
        "\n",
        "# --- Generate \"Dog\" images (class_label=1) ---\n",
        "print(\"\\n--- Generating Dogs ---\")\n",
        "generated_dogs = generate_images(\n",
        "    model,\n",
        "    scheduler,\n",
        "    num_images=16,\n",
        "    class_label=1,  # 1 for dog\n",
        "    guidance_scale=5.0,\n",
        "    device=DEVICE\n",
        ")\n",
        "\n",
        "# Save the dog images\n",
        "save_image(\n",
        "    generated_dogs.float() / 255.0,  # Convert from [0, 255] to [0, 1]\n",
        "    \"generated_dogs_epoch_100.png\",\n",
        "    nrow=4  # Create a 4x4 grid\n",
        ")\n",
        "print(\"Saved dog images to 'generated_dogs_epoch_100.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2ffJMS_V3vx",
        "outputId": "1d5c8324-51c4-4c9e-b6f4-de21d5bc35a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Cats ---\n",
            "Generating 16 images of class 'cat'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: 250it [00:08, 28.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cat images to 'generated_cats_epoch_100.png'\n",
            "\n",
            "--- Generating Dogs ---\n",
            "Generating 16 images of class 'dog'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: 250it [00:08, 28.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved dog images to 'generated_dogs_epoch_100.png'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}